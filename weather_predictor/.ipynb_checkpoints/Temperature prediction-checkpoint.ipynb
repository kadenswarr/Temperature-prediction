{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv(\"C:/Users/Kaden/a_weather_project/weatherdata_grabber/weather_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Datetime'] = (raw_data['Date'] + ' ' + raw_data['Time'])\n",
    "raw_data['Datetime'] = pd.to_datetime(raw_data['Datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = raw_data[['Datetime','Temperature']]\n",
    "weather_data = weather_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "start_d = weather_data.Datetime.max()\n",
    "end_d = weather_data.Datetime.min()\n",
    "\n",
    "dates = pd.Series(pd.date_range(start=start_d, end=end_d, freq='-1H'))\n",
    "missing_dates = dates.loc[~dates.isin(weather_data.Datetime)]\n",
    "\n",
    "h = timedelta(hours=1)\n",
    "missing_rows = []\n",
    "\n",
    "for date in missing_dates:\n",
    "    prev_date = date + h\n",
    "    next_date = date - h\n",
    "    while(weather_data.loc[weather_data['Datetime'] == prev_date].empty):\n",
    "        prev_date = prev_date + h\n",
    "    row_dict = {}\n",
    "    row_dict = weather_data.loc[weather_data['Datetime'] == prev_date].to_dict('records')\n",
    "    row_dict[0].update(Datetime=date)\n",
    "    missing_rows.append(row_dict[0])\n",
    "\n",
    "weather_data = weather_data.append(missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19750, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data = weather_data.sort_values('Datetime', ascending=True)\n",
    "weather_data = weather_data.drop_duplicates()\n",
    "weather_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data['Day'] = weather_data.Datetime.dt.day\n",
    "weather_data['Month'] = weather_data.Datetime.dt.month\n",
    "weather_data['Hour'] = weather_data.Datetime.dt.hour\n",
    "weather_data['DayofYear'] = weather_data.Datetime.dt.dayofyear\n",
    "weather_data['WeekofYear'] = weather_data.Datetime.dt.weekofyear\n",
    "weather_data['Year'] = weather_data.Datetime.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "weather_data['Prev_Temp'] = weather_data['Temperature'].shift()\n",
    "weather_data['Prev_Temp_Diff'] = weather_data.loc[:,'Prev_Temp'].diff()\n",
    "weather_data = weather_data.dropna()\n",
    "\n",
    "features = ['Hour','DayofYear','Month', 'Day','Year','Prev_Temp','Prev_Temp_Diff']\n",
    "X = pd.get_dummies(weather_data[features])\n",
    "y = weather_data.Temperature\n",
    "\n",
    "train_X,test_X,train_y, test_y = train_test_split(X,y,test_size=.2, random_state=23, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def model_eval(model, train_X, train_y, test_X, test_y):\n",
    "    model.fit(train_X,train_y)\n",
    "    predictions = model.predict(test_X)\n",
    "    \n",
    "    print(\"mean squared error %.5f\" % (mean_squared_error(test_y,predictions)))\n",
    "    print(\"mean absolute error %.5f\" %(mean_absolute_error(test_y,predictions)))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 17.64481\n",
      "mean absolute error 2.95367\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=555, n_jobs=-1, random_state=0)\n",
    "p1 = model_eval(model,train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 8.94347\n",
      "mean absolute error 2.10390\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "p4 = model_eval(model,train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 7.82083\n",
      "mean absolute error 1.98407\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model = LGBMRegressor(n_estimatorts=1000,learning_rate=0.1)\n",
    "# model\n",
    "p3 = model_eval(model,train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 7.46213\n",
      "mean absolute error 1.90615\n"
     ]
    }
   ],
   "source": [
    "model = LGBMRegressor(learning_rate=0.07, num_leaves=30)\n",
    "p3 = model_eval(model,train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 11.86167\n",
      "mean absolute error 2.39909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_X)\n",
    "trainX = scaler.transform(train_X)\n",
    "testX = scaler.transform(test_X)\n",
    "\n",
    "model = SGDRegressor()\n",
    "p4 = model_eval(model,trainX,train_y,testX,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 11.75175\n",
      "mean absolute error 2.39753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.1, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, \n",
    "              tol=0.0001, warm_start=False, positive=False, random_state=26, selection='random')\n",
    "p5 = model_eval(model,train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 11.78900\n",
      "mean absolute error 2.40567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge()\n",
    "p5 = model_eval(model,train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error 11.78622\n",
      "mean absolute error 2.42060\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model = ElasticNet()\n",
    "p5 = model_eval(model,train_X,train_y,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Predicted_Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19653</td>\n",
       "      <td>2020-07-03 00:53:00</td>\n",
       "      <td>70.615279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19654</td>\n",
       "      <td>2020-07-03 01:53:00</td>\n",
       "      <td>69.360883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19655</td>\n",
       "      <td>2020-07-03 02:53:00</td>\n",
       "      <td>67.346504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19656</td>\n",
       "      <td>2020-07-03 03:53:00</td>\n",
       "      <td>65.609156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19657</td>\n",
       "      <td>2020-07-03 04:53:00</td>\n",
       "      <td>65.033893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19658</td>\n",
       "      <td>2020-07-03 05:53:00</td>\n",
       "      <td>63.953582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19659</td>\n",
       "      <td>2020-07-03 06:53:00</td>\n",
       "      <td>66.289754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19660</td>\n",
       "      <td>2020-07-03 07:53:00</td>\n",
       "      <td>69.899588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19661</td>\n",
       "      <td>2020-07-03 08:53:00</td>\n",
       "      <td>74.311514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19662</td>\n",
       "      <td>2020-07-03 09:53:00</td>\n",
       "      <td>77.762385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19663</td>\n",
       "      <td>2020-07-03 10:53:00</td>\n",
       "      <td>81.886302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19664</td>\n",
       "      <td>2020-07-03 11:53:00</td>\n",
       "      <td>84.927226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19665</td>\n",
       "      <td>2020-07-03 12:53:00</td>\n",
       "      <td>87.547773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19666</td>\n",
       "      <td>2020-07-03 13:53:00</td>\n",
       "      <td>88.769712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19667</td>\n",
       "      <td>2020-07-03 14:53:00</td>\n",
       "      <td>89.392049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19668</td>\n",
       "      <td>2020-07-03 15:53:00</td>\n",
       "      <td>89.001485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19669</td>\n",
       "      <td>2020-07-03 16:53:00</td>\n",
       "      <td>88.356648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19670</td>\n",
       "      <td>2020-07-03 17:53:00</td>\n",
       "      <td>85.690838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19671</td>\n",
       "      <td>2020-07-03 18:53:00</td>\n",
       "      <td>81.739572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19672</td>\n",
       "      <td>2020-07-03 19:53:00</td>\n",
       "      <td>77.156161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19673</td>\n",
       "      <td>2020-07-03 20:53:00</td>\n",
       "      <td>73.075664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19674</td>\n",
       "      <td>2020-07-03 21:53:00</td>\n",
       "      <td>70.302528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19675</td>\n",
       "      <td>2020-07-03 22:53:00</td>\n",
       "      <td>68.622099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19676</td>\n",
       "      <td>2020-07-03 23:53:00</td>\n",
       "      <td>67.785255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Datetime  Predicted_Temp\n",
       "19653 2020-07-03 00:53:00       70.615279\n",
       "19654 2020-07-03 01:53:00       69.360883\n",
       "19655 2020-07-03 02:53:00       67.346504\n",
       "19656 2020-07-03 03:53:00       65.609156\n",
       "19657 2020-07-03 04:53:00       65.033893\n",
       "19658 2020-07-03 05:53:00       63.953582\n",
       "19659 2020-07-03 06:53:00       66.289754\n",
       "19660 2020-07-03 07:53:00       69.899588\n",
       "19661 2020-07-03 08:53:00       74.311514\n",
       "19662 2020-07-03 09:53:00       77.762385\n",
       "19663 2020-07-03 10:53:00       81.886302\n",
       "19664 2020-07-03 11:53:00       84.927226\n",
       "19665 2020-07-03 12:53:00       87.547773\n",
       "19666 2020-07-03 13:53:00       88.769712\n",
       "19667 2020-07-03 14:53:00       89.392049\n",
       "19668 2020-07-03 15:53:00       89.001485\n",
       "19669 2020-07-03 16:53:00       88.356648\n",
       "19670 2020-07-03 17:53:00       85.690838\n",
       "19671 2020-07-03 18:53:00       81.739572\n",
       "19672 2020-07-03 19:53:00       77.156161\n",
       "19673 2020-07-03 20:53:00       73.075664\n",
       "19674 2020-07-03 21:53:00       70.302528\n",
       "19675 2020-07-03 22:53:00       68.622099\n",
       "19676 2020-07-03 23:53:00       67.785255"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LGBMRegressor(learning_rate=0.07, num_leaves=30)\n",
    "final_model.fit(X,y)\n",
    "\n",
    "one_hour = timedelta(hours=1)\n",
    "to_predict = pd.DataFrame()\n",
    "temp = weather_data[['Temperature','Datetime']].tail(1)\n",
    "temp['Datetime'] = temp['Datetime'] + one_hour\n",
    "temp.reset_index(inplace=True,drop=True)\n",
    "\n",
    "to_predict['Hour'] = temp['Datetime'].dt.hour\n",
    "to_predict['DayofYear'] = temp['Datetime'].dt.dayofyear\n",
    "to_predict['Month'] = temp['Datetime'].dt.month\n",
    "to_predict['Day'] = temp['Datetime'].dt.day\n",
    "to_predict['Year'] = temp['Datetime'].dt.year\n",
    "\n",
    "to_predict['Prev_Temp'] = temp['Temperature']\n",
    "to_predict['Prev_Temp_Diff'] = weather_data['Temperature'].values[-1] - weather_data['Temperature'].values[-2]\n",
    "\n",
    "tom_temps = final_model.predict(to_predict)\n",
    "\n",
    "for i in range(1,24):\n",
    "    to_predict.loc[i] = to_predict.loc[i-1]\n",
    "    to_predict.loc[i].Hour = i\n",
    "    to_predict.loc[i].Prev_Temp = round(tom_temps.item(i-1))\n",
    "    to_predict.loc[i].Prev_Temp_Diff = to_predict.loc[i].Prev_Temp - to_predict.loc[i-1].Prev_Temp\n",
    "    tom_temps = final_model.predict(to_predict)\n",
    "\n",
    "predicted_temps = pd.DataFrame()\n",
    "predicted_temps['Datetime'] = weather_data['Datetime'].tail(24) + timedelta(days=1)\n",
    "predicted_temps['Predicted_Temp'] = tom_temps\n",
    "predicted_temps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
